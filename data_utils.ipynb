{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import Counter\n",
    "#import gensim\n",
    "import jieba\n",
    "import json\n",
    "import pickle\n",
    "import csv\n",
    "import numpy as np\n",
    "#from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total courses 697\n",
      "total courses 705\n"
     ]
    }
   ],
   "source": [
    "# load user video act\n",
    "json_file = r\"C:\\Users\\user\\Desktop\\Heterogeneous\\MOOCCube\\additional_information\\user_video_act.json\"\n",
    "\n",
    "with open(json_file, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# load course name dict\n",
    "with open(r\"C:\\Users\\user\\Desktop\\Heterogeneous\\MOOCCube\\entities\\course.json\", \"r\", encoding=\"utf8\") as f:\n",
    "    courses = f.readlines()\n",
    "    \n",
    "course_dict = dict()\n",
    "for c in courses:\n",
    "    json_data = json.loads(c)\n",
    "    course_dict[json_data[\"id\"]] = json_data[\"name\"]\n",
    "\n",
    "# load course-teacher relationship to dict\n",
    "def get_course_dict(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf8\") as f:\n",
    "        tc_rels = f.readlines()\n",
    "    tc_rel_dict = dict()\n",
    "    for tc_rel in tc_rels:\n",
    "        tc_rel = tc_rel.strip().split(\"\\t\")\n",
    "        if tc_rel[1] not in tc_rel_dict:\n",
    "            tc_rel_dict[tc_rel[1]] = [tc_rel[0]]\n",
    "        else:\n",
    "            tc_rel_dict[tc_rel[1]].append(tc_rel[0])\n",
    "        \n",
    "    return tc_rel_dict\n",
    "\n",
    "tc_rel_dict = get_course_dict(r\"C:\\Users\\user\\Desktop\\Heterogeneous\\MOOCCube\\relations\\teacher-course.json\")\n",
    "print(\"total courses\", len(tc_rel_dict))\n",
    "\n",
    "sc_rel_dict = get_course_dict(r\"C:\\Users\\user\\Desktop\\Heterogeneous\\MOOCCube\\relations\\school-course.json\")\n",
    "print(\"total courses\", len(sc_rel_dict))\n",
    "\n",
    "# load video concepts\n",
    "vc_df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\Heterogeneous\\MOOCCube\\relations\\video-concept.json\",\n",
    "                   header=None,\n",
    "                   delimiter=\"\\t\",\n",
    "                   names=[\"video\", \"concept\"])\n",
    "vc_dict = vc_df.groupby('video')['concept'].apply(list).to_dict()\n",
    "\n",
    "# load course concepts\n",
    "cc_df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\Heterogeneous\\MOOCCube\\relations\\course-concept.json\",\n",
    "                   header=None,\n",
    "                   delimiter=\"\\t\",\n",
    "                   names=[\"course\", \"concept\"])\n",
    "cc_dict = cc_df.groupby('course')['concept'].apply(list).to_dict()\n",
    "\n",
    "# load course video\n",
    "cv_df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\Heterogeneous\\MOOCCube\\relations\\course-video.json\",\n",
    "                   header=None,\n",
    "                   delimiter=\"\\t\",\n",
    "                   names=[\"course\", \"video\"])\n",
    "cv_dict = cv_df.groupby(\"course\")[\"video\"].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total users 48640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48640/48640 [00:24<00:00, 1982.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4874298, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"total users\", len(lines))\n",
    "user_dfs = list()\n",
    "\n",
    "for l in tqdm(lines):\n",
    "    json_data = json.loads(l)\n",
    "#     print(json_data)\n",
    "\n",
    "    activities = json_data[\"activity\"]\n",
    "    course_ids = list()\n",
    "    video_ids = list()\n",
    "    local_start_times = list()\n",
    "    concepts = list()\n",
    "    cnames = list()\n",
    "    teachers = list()\n",
    "    schools = list()\n",
    "    \n",
    "    for a in activities:\n",
    "        cnames.append(course_dict[a[\"course_id\"]]) if a[\"course_id\"] in course_dict else cnames.append(\"\")\n",
    "        course_ids.append(a[\"course_id\"])\n",
    "        video_ids.append(a[\"video_id\"])\n",
    "        local_start_times.append(a[\"local_start_time\"])\n",
    "        concepts.append(vc_dict[a[\"video_id\"]]) if a[\"video_id\"] in vc_dict else concepts.append([\"\"])\n",
    "        teachers.append(tc_rel_dict[a[\"course_id\"]]) if a[\"course_id\"] in tc_rel_dict else teachers.append([\"\"])\n",
    "        schools.append(sc_rel_dict[a[\"course_id\"]][0]) if a[\"course_id\"] in sc_rel_dict else schools.append(\"\")\n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "        \"id\": json_data[\"id\"],\n",
    "        \"cname\": cnames,\n",
    "        \"cid\": course_ids,\n",
    "        \"vid\": video_ids,\n",
    "        \"concepts\": concepts,\n",
    "        \"teachers\": teachers,\n",
    "        \"schools\": schools,\n",
    "        \"local_start_time\": local_start_times\n",
    "    })\n",
    "    df.sort_values(\"local_start_time\", inplace=True)\n",
    "    \n",
    "#     display(df)\n",
    "    user_dfs.append(df)\n",
    "\n",
    "# convert to total df\n",
    "total_df = pd.concat(user_dfs,ignore_index=True)\n",
    "total_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130\n",
      "(311743, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2130/2130 [00:19<00:00, 109.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290024, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# max '2020-04-17 17:25:48'\n",
    "bad_formatted_users = list(total_df[total_df[\"local_start_time\"]<\"2017-01-01 00:00:00\"]['id'].unique())\n",
    "user_in_trainingperiod = list(total_df[(total_df[\"local_start_time\"]>='2017-01-01 00:00:00') & (total_df[\"local_start_time\"]<='2019-11-01 00:00:00')]['id'].unique())\n",
    "user_in_testperiod = list(total_df[total_df[\"local_start_time\"]>'2019-11-01 00:00:00']['id'].unique())\n",
    "selected_users = [u for u in user_in_testperiod if u in user_in_trainingperiod if u not in bad_formatted_users]\n",
    "print(len(selected_users))\n",
    "\n",
    "filtered_df = total_df[total_df[\"id\"].isin(selected_users)]\n",
    "print(filtered_df.shape)\n",
    "\n",
    "# check whether there is at least one concept in the testing period that is not in the training period\n",
    "need_to_filter = list()\n",
    "for u in tqdm(selected_users):\n",
    "    udf = filtered_df[filtered_df[\"id\"]==u]\n",
    "    train_udf = udf[(udf[\"local_start_time\"]>='2017-01-01 00:00:00') & (udf[\"local_start_time\"]<='2019-11-01 00:00:00')]\n",
    "    test_udf = udf[udf[\"local_start_time\"]>'2019-11-01 00:00:00']\n",
    "    train_concepts = list(set([x for sublist in train_udf[\"concepts\"].values for x in sublist]))\n",
    "    test_concepts = list(set([x for sublist in test_udf[\"concepts\"].values for x in sublist]))\n",
    "    if len([x for x in test_concepts if x not in train_concepts])==0:\n",
    "#         print(\"unsatisfied user:\", u)\n",
    "        need_to_filter.append(u)\n",
    "\n",
    "filtered_users = [u for u in selected_users if u not in need_to_filter]\n",
    "filtered_df = filtered_df[filtered_df[\"id\"].isin(filtered_users)]\n",
    "print(filtered_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df= total_df[total_df[\"local_start_time\"]>'2019-11-01 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Entity Statistics -----------------\n",
      "filtered df (290024, 8)\n",
      "total users 2005\n",
      "total courses 600\n",
      "total videos 22403\n",
      "total schools 137\n",
      "distinct concepts 21037\n",
      "total teachers 1385\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------- Entity Statistics -----------------\")\n",
    "distinct_concepts = list(set([c for sublist in filtered_df[\"concepts\"].values for c in sublist if len(c)>0]))\n",
    "#test_distinct_concepts = list(set([c for sublist in test_df[\"concepts\"].values for c in sublist if len(c)>0]))\n",
    "print(\"filtered df\", filtered_df.shape)\n",
    "print(\"total users\", len(filtered_df[\"id\"].unique()))\n",
    "print(\"total courses\", len(filtered_df[\"cid\"].unique()))\n",
    "print(\"total videos\", len(filtered_df[\"vid\"].unique()))\n",
    "print(\"total schools\", len(filtered_df[\"schools\"].unique()))\n",
    "print(\"distinct concepts\", len(distinct_concepts))\n",
    "t_list = filtered_df[\"teachers\"].values\n",
    "flattend_t_list = list(set([t for sublist in t_list for t in sublist]))\n",
    "print(\"total teachers\", len(flattend_t_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # store distinct concept for embedding analysis\n",
    "# with open(r\"concept21037.txt\", \"w\") as f:\n",
    "#     for c in distinct_concepts:\n",
    "#         f.write(\"{}\\n\".format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Relation Statistics based on filtered courses -----------------\n",
      "user-course relations 13696\n",
      "course-video relations 42117\n",
      "teacher-course relations 1875\n",
      "34506\n",
      "video-concept relations 295475\n",
      "course-concept relations 150811\n",
      "course - C_course-v1:RiceX+Phys102x+sp does not have concepts\n",
      "course - C_course-v1:TsinghuaX+Thesis2018+sp does not have concepts\n",
      "course - C_course-v1:UC_BerkeleyX+ColWri2_1x_2015_T1+2019_T1 does not have concepts\n",
      "course - C_course-v1:HUBU+2017022703X+sp does not have concepts\n",
      "course - C_course-v1:TsinghuaX+TsinghuaMandarin01+sp does not have concepts\n",
      "course - C_course-v1:UC_BerkeleyX+CS169_2x+sp does not have concepts\n",
      "course - C_course-v1:ZAFU+20171218+2019_T1 does not have concepts\n",
      "course - C_course-v1:qhnu+20181212x+2019_T1 does not have concepts\n",
      "course - C_course-v1:SDSNAssociation+C21001+sp does not have concepts\n",
      "course - C_course-v1:XJTU+20171025001+2019_T1 does not have concepts\n",
      "course - C_course-v1:NUDT+05028103+2018_T2 does not have concepts\n",
      "course - C_course-v1:qhnu+20181212x+2018_T2 does not have concepts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21037, 600)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------------- Relation Statistics based on filtered courses -----------------\")\n",
    "print(\"user-course relations\", filtered_df.groupby(['id','cid']).size().shape[0])\n",
    "\n",
    "# relations based on filtered course \n",
    "courses = filtered_df[\"cid\"].unique()\n",
    "# course video\n",
    "filtered_cv_dict = dict(filter(lambda elem: elem[0] in courses, cv_dict.items()))\n",
    "print(\"course-video relations\", sum([len(x) for x in filtered_cv_dict.values()]))\n",
    "# teacher course\n",
    "filtered_tc_rel_dict = dict(filter(lambda elem: elem[0] in courses, tc_rel_dict.items()))\n",
    "print(\"teacher-course relations\", sum([len(x) for x in filtered_tc_rel_dict.values()]))\n",
    "# video concept\n",
    "videos_in_filtered_courses = list(set([x for sublist in filtered_cv_dict.values() for x in sublist]))\n",
    "print(len(videos_in_filtered_courses))\n",
    "filtered_vc_rel_dict = dict(filter(lambda elem: elem[0] in videos_in_filtered_courses, vc_dict.items()))\n",
    "print(\"video-concept relations\", sum([len(x) for x in filtered_vc_rel_dict.values()]))\n",
    "# course concept\n",
    "filtered_cc_rel_dict = dict(filter(lambda elem: elem[0] in courses, cc_dict.items()))\n",
    "print(\"course-concept relations\", sum([len(x) for x in filtered_cc_rel_dict.values()]))\n",
    "# store KC.p\n",
    "concepts = distinct_concepts\n",
    "course2index = dict(zip(courses, list(range(len(courses)))))\n",
    "concept2index = dict(zip(concepts, list(range(len(concepts)))))\n",
    "\n",
    "cc_list = list()\n",
    "for c in courses:\n",
    "    cvec = np.zeros(len(concepts))\n",
    "    if c in filtered_cc_rel_dict:\n",
    "        indices = [concept2index[_] for _ in filtered_cc_rel_dict[c] if _ in concept2index]\n",
    "        cvec[indices] = 1\n",
    "    else:\n",
    "        print(\"course - {} does not have concepts\".format(c))\n",
    "    cc_list.append(cvec)\n",
    "    \n",
    "cc_np = np.array(cc_list).T\n",
    "cc_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ua(udf, column, index_dict):\n",
    "\n",
    "    if isinstance(udf[column].values[0], list):\n",
    "        uconcepts = list([c for sublist in udf[column].values for c in sublist if len(c)>0])\n",
    "    else:\n",
    "#         print(udf[column].values)\n",
    "        uconcepts = list(c for c in udf[column].values if len(c)>0)\n",
    "    uconcepts = Counter(uconcepts)\n",
    "    uconcepts = dict(uconcepts)\n",
    "#     print(len(uconcepts))\n",
    "    \n",
    "    uconcepts_indices = [index_dict[c] for c in uconcepts.keys()]\n",
    "    uvec = np.zeros(len(index_dict))\n",
    "#     uvec[uconcepts_indices] = 1\n",
    "    np.put(a=uvec, ind=uconcepts_indices, v=list(uconcepts.values()))\n",
    "    assert len(uconcepts_indices) == (uvec>0).sum()\n",
    "    return uvec\n",
    "\n",
    "def radom_negative_sample(user_action, item_size):\n",
    "    \"\"\"to get (user_size, 100, 2), 100th item is positive one\"\"\"\n",
    "    negative_sample = []\n",
    "    for u in user_action:\n",
    "        sample = []\n",
    "        i = 0\n",
    "        while i < 99:\n",
    "            t = random.randint(0, item_size-1)\n",
    "            if t not in user_action[u]:\n",
    "                sample.append([u, t])\n",
    "                i += 1\n",
    "        sample.append([u, user_action[u][-1]])\n",
    "        negative_sample.append(sample)\n",
    "    return np.array(negative_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2005 [00:00<?, ?it/s]C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\2867057873.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  udf_train.sort_values([\"local_start_time\"], inplace=True)\n",
      "100%|██████████| 2005/2005 [00:19<00:00, 105.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# creat user-index, concept-index dict\n",
    "users = filtered_df[\"id\"].unique()\n",
    "user2index = dict(zip(users, list(range(len(users)))))\n",
    "concepts = distinct_concepts\n",
    "concept2index = dict(zip(concepts, list(range(len(concepts)))))\n",
    "courses = filtered_df[\"cid\"].unique()\n",
    "course2index = dict(zip(courses, list(range(len(courses)))))\n",
    "teachers = flattend_t_list\n",
    "teacher2index = dict(zip(teachers, list(range(len(teachers)))))\n",
    "schools = filtered_df[\"schools\"].unique()\n",
    "school2index = dict(zip(schools, list(range(len(schools)))))\n",
    "videos = filtered_df[\"vid\"].unique()\n",
    "video2index = dict(zip(videos, list(range(len(videos)))))\n",
    "\n",
    "\n",
    "user_action = list()\n",
    "rating_matrix = list()\n",
    "adjacency_matrix = list()\n",
    "user_course = list()\n",
    "user_teacher = list()\n",
    "user_school = list()\n",
    "user_video = list()\n",
    "user_concept_dict = dict()\n",
    "\n",
    "time_filtered_df = filtered_df[(filtered_df[\"local_start_time\"]>='2017-01-01 00:00:00') & (filtered_df[\"local_start_time\"]<='2019-11-01 00:00:00')]\n",
    "\n",
    "for i in tqdm(range(len(users))):\n",
    "    # user_action\n",
    "    udf = filtered_df[filtered_df.id==users[i]]    \n",
    "    udf_train = udf[(udf[\"local_start_time\"]>='2017-01-01 00:00:00') & (udf[\"local_start_time\"]<='2019-11-01 00:00:00')]\n",
    "    uvec_train = get_ua(udf_train, 'concepts', concept2index)\n",
    "    adjacency_matrix.append(uvec_train)\n",
    "    # rating_matrix\n",
    "    udf_train.sort_values([\"local_start_time\"], inplace=True)\n",
    "    con_list = udf_train[\"concepts\"].values\n",
    "    learning_time = udf_train[\"local_start_time\"].values\n",
    "    con_dict = dict()\n",
    "    for ind, clist in enumerate(con_list):\n",
    "        time = learning_time[ind]\n",
    "        for c in clist:\n",
    "            if c not in con_dict and len(c)>0:\n",
    "                con_dict[c] = time\n",
    "    uvec_train_ = uvec_train.copy()\n",
    "    uvec_train_[concept2index[list(con_dict.keys())[-1]]] = 0\n",
    "    rating_matrix.append(uvec_train_)\n",
    "\n",
    "    user_concept_dict[i] = [concept2index[c] for c in list(con_dict.keys())]\n",
    "\n",
    "    user_action.append(get_ua(udf, 'concepts', concept2index))\n",
    "    user_course.append(get_ua(udf_train, 'cid', course2index))\n",
    "    user_school.append(get_ua(udf_train, 'schools', school2index))\n",
    "    user_teacher.append(get_ua(udf_train, 'teachers', teacher2index))\n",
    "    user_video.append(get_ua(udf_train, 'vid', video2index))\n",
    "    \n",
    "matrices = [adjacency_matrix, user_course, user_teacher, user_school, user_video]\n",
    "matrices = [(np.array(matrix) > 0).astype(np.int8) for matrix in matrices]\n",
    "adjacency_matrix, user_course, user_teacher, user_school, user_video = matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/600 [00:00<?, ?it/s]C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\244062866.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  udf_train.sort_values([\"local_start_time\"], inplace=True)\n",
      "100%|██████████| 600/600 [00:10<00:00, 54.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# courses\n",
    "course_action = list()\n",
    "course_teacher = list()\n",
    "course_video = list()\n",
    "for i in tqdm(range(len(courses))):\n",
    "    try:\n",
    "        udf = filtered_df[filtered_df.cid==courses[i]]   \n",
    "        udf_train = udf[(udf[\"local_start_time\"]>='2017-01-01 00:00:00') & (udf[\"local_start_time\"]<='2019-11-01 00:00:00')] \n",
    "        uvec_train = get_ua(udf_train, 'concepts', concept2index)\n",
    "        udf_train.sort_values([\"local_start_time\"], inplace=True)\n",
    "\n",
    "        course_action.append(get_ua(udf, 'concepts', concept2index))\n",
    "        course_teacher.append(get_ua(udf_train, 'teachers', teacher2index))\n",
    "        course_video.append(get_ua(udf_train, 'vid', video2index))\n",
    "    except : \n",
    "        course_action.append(np.zeros(len(concept2index)))\n",
    "        course_teacher.append(np.zeros(len(teacher2index)))\n",
    "        course_video.append(np.zeros(len(video2index)))\n",
    "\n",
    "course_action = np.vstack(course_action)\n",
    "course_teacher = np.vstack(course_teacher)\n",
    "course_video = np.vstack(course_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1385 [00:00<?, ?it/s]C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\1989059790.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  udf_train.sort_values([\"local_start_time\"], inplace=True)\n",
      "100%|██████████| 1385/1385 [00:29<00:00, 46.66it/s]\n"
     ]
    }
   ],
   "source": [
    "teacher_action = list()\n",
    "teacher_video = list()\n",
    "df_exploded = filtered_df.explode('teachers')\n",
    "for i in tqdm(range(len(teachers))):\n",
    "    try:\n",
    "        udf = df_exploded[df_exploded.teachers==teachers[i]]  \n",
    "        udf_train = udf[(udf[\"local_start_time\"]>='2017-01-01 00:00:00') & (udf[\"local_start_time\"]<='2019-11-01 00:00:00')]  \n",
    "        uvec_train = get_ua(udf_train, 'concepts', concept2index)\n",
    "        udf_train.sort_values([\"local_start_time\"], inplace=True)\n",
    "        \n",
    "        teacher_action.append(get_ua(udf, 'concepts', concept2index))\n",
    "        teacher_video.append(get_ua(udf_train, 'vid', video2index))\n",
    "    except : \n",
    "        teacher_action.append(np.zeros(len(concept2index)))\n",
    "        teacher_video.append(np.zeros(len(video2index)))\n",
    "teacher_action = np.vstack(teacher_action)\n",
    "teacher_video = np.vstack(teacher_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22403/22403 [05:36<00:00, 66.65it/s]\n"
     ]
    }
   ],
   "source": [
    "video_action =  list()\n",
    "for i in tqdm(range(len(videos))):\n",
    "    try:\n",
    "        udf = time_filtered_df[time_filtered_df.vid==videos[i]]    \n",
    "        udf_train = udf[(udf[\"local_start_time\"]>='2017-01-01 00:00:00') & (udf[\"local_start_time\"]<='2019-11-01 00:00:00')]\n",
    "        uvec_train = get_ua(udf_train, 'concepts', concept2index)\n",
    "        udf_train.sort_values([\"local_start_time\"], inplace=True)\n",
    "        video_action.append(get_ua(udf, 'concepts', concept2index))\n",
    "    except : \n",
    "        video_action.append(np.zeros(len(concept2index)))\n",
    "video_action = np.vstack(video_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47430, 47430)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "user_length = adjacency_matrix.shape[0]\n",
    "kc_length =  adjacency_matrix.shape[1]\n",
    "course_length =  user_course.shape[1]\n",
    "teacher_length =  user_teacher.shape[1]\n",
    "video_length = user_video.shape[1]\n",
    "\n",
    "total_rows = user_length +kc_length+course_length+teacher_length+video_length\n",
    "\n",
    "combined_matrix = np.zeros((total_rows, total_rows), dtype=np.int8)\n",
    "\n",
    "col_0 = user_length\n",
    "col_1 = col_0 + kc_length\n",
    "col_2 = col_1 + course_length\n",
    "col_3 = col_2 + teacher_length\n",
    "col_4 = col_3 + video_length\n",
    "\n",
    "row_0 = user_length\n",
    "row_1 = row_0 + kc_length\n",
    "row_2 = row_1 + course_length\n",
    "row_3 = row_2 + teacher_length\n",
    "row_4 = row_3 + video_length\n",
    "\n",
    "combined_matrix[:row_0, col_0:col_1] = adjacency_matrix\n",
    "combined_matrix[:row_0, col_1:col_2] = user_course\n",
    "combined_matrix[:row_0, col_2:col_3] = user_teacher\n",
    "combined_matrix[:row_0, col_3:col_4] = user_video\n",
    "\n",
    "# course  \n",
    "combined_matrix[row_0:row_1, col_1:col_2] = course_action.T\n",
    "combined_matrix[row_2:row_3, col_1:col_2] = course_teacher.T\n",
    "combined_matrix[row_3:row_4, col_1:col_2] = course_video.T\n",
    "\n",
    "# teacher\n",
    "combined_matrix[row_0:row_1, col_2:col_3] = teacher_action.T\n",
    "combined_matrix[row_3:row_4, col_2:col_3] = teacher_video.T\n",
    "\n",
    "#video \n",
    "\n",
    "combined_matrix[row_0:row_1, col_3:col_4] = video_action.T\n",
    "\n",
    "print(combined_matrix.shape)\n",
    "combined_matrix = combined_matrix+combined_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 397,  459,  749, 1164, 1285, 1473], dtype=int64),)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacency_matrix.T[5877-user_length].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8205\n",
      "10980\n",
      "11021\n",
      "16422\n",
      "16695\n",
      "18537\n",
      "20277\n",
      "22432\n",
      "23291\n",
      "23538\n",
      "23566\n",
      "23617\n",
      "23841\n",
      "23934\n",
      "24062\n",
      "24149\n",
      "24194\n",
      "24291\n",
      "24394\n",
      "24527\n",
      "24590\n",
      "24765\n",
      "24770\n",
      "24813\n",
      "24943\n",
      "27919\n",
      "27920\n",
      "27922\n",
      "27923\n",
      "27924\n",
      "27925\n",
      "27926\n",
      "27927\n",
      "27928\n",
      "27929\n",
      "27930\n",
      "27931\n",
      "27932\n",
      "27933\n",
      "27934\n",
      "27935\n",
      "27936\n",
      "27937\n",
      "27938\n",
      "27940\n",
      "27941\n",
      "27942\n",
      "27943\n",
      "27944\n",
      "27945\n",
      "27946\n",
      "27947\n",
      "27948\n",
      "27950\n",
      "27951\n",
      "27952\n",
      "31519\n",
      "31543\n",
      "31544\n",
      "32062\n",
      "32063\n",
      "32064\n",
      "32065\n",
      "32066\n",
      "32069\n",
      "32070\n",
      "32071\n",
      "32072\n",
      "32073\n",
      "32074\n",
      "32075\n",
      "32076\n",
      "32077\n",
      "32078\n",
      "32079\n",
      "32080\n",
      "32081\n",
      "32082\n",
      "32083\n",
      "32084\n",
      "32085\n",
      "32086\n",
      "32087\n",
      "32088\n",
      "32121\n",
      "32128\n",
      "32143\n",
      "32416\n",
      "32417\n",
      "32718\n",
      "33048\n",
      "34456\n",
      "34656\n",
      "34668\n",
      "34705\n",
      "34706\n",
      "34707\n",
      "34708\n",
      "34709\n",
      "34710\n",
      "34872\n",
      "35116\n",
      "35136\n",
      "35557\n",
      "35562\n",
      "35571\n",
      "35582\n",
      "35583\n",
      "35586\n",
      "35594\n",
      "35600\n",
      "35602\n",
      "35603\n",
      "35610\n",
      "35612\n",
      "35623\n",
      "35624\n",
      "35625\n",
      "35641\n",
      "36039\n",
      "36059\n",
      "36060\n",
      "36505\n",
      "36601\n",
      "36846\n",
      "37086\n",
      "37087\n",
      "37088\n",
      "37103\n",
      "37245\n",
      "37322\n",
      "37559\n",
      "37560\n",
      "37561\n",
      "37565\n",
      "37566\n",
      "37572\n",
      "37574\n",
      "37575\n",
      "37605\n",
      "37766\n",
      "37887\n",
      "37888\n",
      "37889\n",
      "37890\n",
      "37891\n",
      "37893\n",
      "37894\n",
      "37895\n",
      "37896\n",
      "37897\n",
      "37898\n",
      "37981\n",
      "38619\n",
      "38620\n",
      "38621\n",
      "38622\n",
      "38639\n",
      "38640\n",
      "38642\n",
      "38645\n",
      "38646\n",
      "38647\n",
      "38648\n",
      "38649\n",
      "38650\n",
      "38651\n",
      "38658\n",
      "38659\n",
      "38660\n",
      "38661\n",
      "38682\n",
      "38721\n",
      "38722\n",
      "38723\n",
      "38797\n",
      "38798\n",
      "38929\n",
      "38930\n",
      "38931\n",
      "38932\n",
      "38948\n",
      "39426\n",
      "39427\n",
      "39428\n",
      "39429\n",
      "39430\n",
      "39431\n",
      "39432\n",
      "39434\n",
      "39435\n",
      "39436\n",
      "39462\n",
      "39628\n",
      "39629\n",
      "39630\n",
      "39631\n",
      "39648\n",
      "39658\n",
      "39659\n",
      "39660\n",
      "39661\n",
      "39847\n",
      "39941\n",
      "39942\n",
      "39943\n",
      "39945\n",
      "40009\n",
      "40010\n",
      "40011\n",
      "40012\n",
      "40014\n",
      "40016\n",
      "40136\n",
      "40185\n",
      "40186\n",
      "40187\n",
      "40188\n",
      "40189\n",
      "40190\n",
      "40191\n",
      "40192\n",
      "40193\n",
      "40207\n",
      "40208\n",
      "40209\n",
      "40210\n",
      "40211\n",
      "40298\n",
      "40305\n",
      "40306\n",
      "40307\n",
      "40308\n",
      "40309\n",
      "40310\n",
      "40312\n",
      "40313\n",
      "40365\n",
      "40366\n",
      "40368\n",
      "40370\n",
      "40373\n",
      "40374\n",
      "40377\n",
      "40379\n",
      "40380\n",
      "40381\n",
      "40385\n",
      "40387\n",
      "40423\n",
      "40424\n",
      "40429\n",
      "40433\n",
      "40435\n",
      "40436\n",
      "40437\n",
      "40438\n",
      "40439\n",
      "40440\n",
      "40441\n",
      "40442\n",
      "40443\n",
      "40444\n",
      "40445\n",
      "40446\n",
      "40448\n",
      "40449\n",
      "40450\n",
      "40451\n",
      "40452\n",
      "40456\n",
      "40474\n",
      "40475\n",
      "40522\n",
      "40528\n",
      "40575\n",
      "40580\n",
      "40687\n",
      "40794\n",
      "40795\n",
      "40796\n",
      "40797\n",
      "40798\n",
      "40799\n",
      "40801\n",
      "40802\n",
      "40803\n",
      "40804\n",
      "40805\n",
      "40806\n",
      "40807\n",
      "40808\n",
      "40809\n",
      "40810\n",
      "40815\n",
      "40817\n",
      "40819\n",
      "40820\n",
      "40824\n",
      "40828\n",
      "40829\n",
      "40830\n",
      "40831\n",
      "40832\n",
      "40833\n",
      "40834\n",
      "40835\n",
      "40836\n",
      "40837\n",
      "40838\n",
      "40839\n",
      "40840\n",
      "40841\n",
      "40844\n",
      "40845\n",
      "40846\n",
      "40847\n",
      "40848\n",
      "40849\n",
      "40850\n",
      "40851\n",
      "40852\n",
      "40853\n",
      "40855\n",
      "40856\n",
      "40857\n",
      "40858\n",
      "40859\n",
      "40860\n",
      "40861\n",
      "40862\n",
      "40863\n",
      "40864\n",
      "40865\n",
      "40894\n",
      "41033\n",
      "41149\n",
      "41156\n",
      "41157\n",
      "41158\n",
      "41159\n",
      "41160\n",
      "41161\n",
      "41165\n",
      "41174\n",
      "41267\n",
      "41292\n",
      "41375\n",
      "41376\n",
      "41377\n",
      "41378\n",
      "41379\n",
      "41380\n",
      "41381\n",
      "41382\n",
      "41383\n",
      "41384\n",
      "41385\n",
      "41386\n",
      "41387\n",
      "41388\n",
      "41423\n",
      "41424\n",
      "41425\n",
      "41426\n",
      "41792\n",
      "41802\n",
      "42015\n",
      "42049\n",
      "42056\n",
      "42057\n",
      "42058\n",
      "42186\n",
      "42187\n",
      "42241\n",
      "42242\n",
      "42243\n",
      "42244\n",
      "42245\n",
      "42246\n",
      "42247\n",
      "42248\n",
      "42261\n",
      "42264\n",
      "42332\n",
      "42333\n",
      "42337\n",
      "42385\n",
      "42386\n",
      "42387\n",
      "42388\n",
      "42422\n",
      "42423\n",
      "42424\n",
      "42425\n",
      "42426\n",
      "42427\n",
      "42428\n",
      "42429\n",
      "42431\n",
      "42433\n",
      "42434\n",
      "42435\n",
      "42437\n",
      "42438\n",
      "42439\n",
      "42440\n",
      "42442\n",
      "42447\n",
      "42449\n",
      "42450\n",
      "42451\n",
      "42453\n",
      "42455\n",
      "42456\n",
      "42457\n",
      "42459\n",
      "42460\n",
      "42461\n",
      "42462\n",
      "42463\n",
      "42465\n",
      "42466\n",
      "42467\n",
      "42469\n",
      "42470\n",
      "42471\n",
      "42473\n",
      "42475\n",
      "42478\n",
      "42481\n",
      "42482\n",
      "42483\n",
      "42484\n",
      "42488\n",
      "42491\n",
      "42492\n",
      "42494\n",
      "42495\n",
      "42496\n",
      "42498\n",
      "42573\n",
      "42574\n",
      "42575\n",
      "42576\n",
      "42577\n",
      "42578\n",
      "42581\n",
      "42631\n",
      "42806\n",
      "42807\n",
      "42808\n",
      "42810\n",
      "42811\n",
      "42812\n",
      "42813\n",
      "42829\n",
      "42830\n",
      "42964\n",
      "42965\n",
      "42966\n",
      "43012\n",
      "43013\n",
      "43014\n",
      "43100\n",
      "43101\n",
      "43102\n",
      "43103\n",
      "43104\n",
      "43105\n",
      "43106\n",
      "43107\n",
      "43108\n",
      "43109\n",
      "43110\n",
      "43111\n",
      "43112\n",
      "43113\n",
      "43114\n",
      "43115\n",
      "43231\n",
      "43232\n",
      "43233\n",
      "43234\n",
      "43235\n",
      "43236\n",
      "43237\n",
      "43240\n",
      "43241\n",
      "43242\n",
      "43269\n",
      "43270\n",
      "43271\n",
      "43299\n",
      "43312\n",
      "43314\n",
      "43315\n",
      "43316\n",
      "43317\n",
      "43318\n",
      "43319\n",
      "43320\n",
      "43322\n",
      "43323\n",
      "43324\n",
      "43325\n",
      "43326\n",
      "43327\n",
      "43328\n",
      "43329\n",
      "43330\n",
      "43331\n",
      "43332\n",
      "43333\n",
      "43334\n",
      "43335\n",
      "43336\n",
      "43337\n",
      "43340\n",
      "43341\n",
      "43428\n",
      "43437\n",
      "43438\n",
      "43439\n",
      "43440\n",
      "43441\n",
      "43442\n",
      "43443\n",
      "43444\n",
      "43445\n",
      "43446\n",
      "43447\n",
      "43448\n",
      "43449\n",
      "43450\n",
      "43451\n",
      "43452\n",
      "43660\n",
      "43661\n",
      "43665\n",
      "43680\n",
      "43682\n",
      "43697\n",
      "43698\n",
      "43699\n",
      "43700\n",
      "43701\n",
      "43702\n",
      "43703\n",
      "43704\n",
      "43705\n",
      "43706\n",
      "43707\n",
      "43708\n",
      "43709\n",
      "43710\n",
      "43768\n",
      "43821\n",
      "43836\n",
      "43837\n",
      "43838\n",
      "43839\n",
      "43840\n",
      "43841\n",
      "43885\n",
      "43990\n",
      "44058\n",
      "44059\n",
      "44060\n",
      "44061\n",
      "44062\n",
      "44063\n",
      "44064\n",
      "44065\n",
      "44066\n",
      "44067\n",
      "44068\n",
      "44069\n",
      "44154\n",
      "44155\n",
      "44156\n",
      "44157\n",
      "44158\n",
      "44159\n",
      "44187\n",
      "44199\n",
      "44200\n",
      "44279\n",
      "44280\n",
      "44281\n",
      "44282\n",
      "44283\n",
      "44284\n",
      "44285\n",
      "44286\n",
      "44287\n",
      "44288\n",
      "44289\n",
      "44290\n",
      "44291\n",
      "44292\n",
      "44293\n",
      "44294\n",
      "44295\n",
      "44296\n",
      "44297\n",
      "44298\n",
      "44299\n",
      "44300\n",
      "44301\n",
      "44302\n",
      "44303\n",
      "44304\n",
      "44305\n",
      "44306\n",
      "44307\n",
      "44308\n",
      "44309\n",
      "44310\n",
      "44311\n",
      "44312\n",
      "44313\n",
      "44314\n",
      "44315\n",
      "44316\n",
      "44317\n",
      "44318\n",
      "44319\n",
      "44320\n",
      "44362\n",
      "44494\n",
      "44495\n",
      "44496\n",
      "44497\n",
      "44537\n",
      "44555\n",
      "44701\n",
      "44741\n",
      "44861\n",
      "44950\n",
      "44951\n",
      "44952\n",
      "44953\n",
      "44954\n",
      "44955\n",
      "44956\n",
      "44957\n",
      "44958\n",
      "44959\n",
      "44960\n",
      "44961\n",
      "44974\n",
      "44976\n",
      "45130\n",
      "45131\n",
      "45132\n",
      "45136\n",
      "45137\n",
      "45138\n",
      "45139\n",
      "45160\n",
      "45161\n",
      "45162\n",
      "45163\n",
      "45164\n",
      "45165\n",
      "45166\n",
      "45167\n",
      "45168\n",
      "45169\n",
      "45170\n",
      "45171\n",
      "45172\n",
      "45173\n",
      "45174\n",
      "45175\n",
      "45176\n",
      "45212\n",
      "45213\n",
      "45214\n",
      "45215\n",
      "45216\n",
      "45227\n",
      "45230\n",
      "45231\n",
      "45232\n",
      "45233\n",
      "45234\n",
      "45235\n",
      "45236\n",
      "45237\n",
      "45238\n",
      "45239\n",
      "45240\n",
      "45241\n",
      "45242\n",
      "45394\n",
      "45395\n",
      "45396\n",
      "45481\n",
      "45482\n",
      "45484\n",
      "45485\n",
      "45486\n",
      "45488\n",
      "45489\n",
      "45678\n",
      "45679\n",
      "45680\n",
      "45681\n",
      "45682\n",
      "45694\n",
      "45697\n",
      "45706\n",
      "45707\n",
      "45751\n",
      "45752\n",
      "45755\n",
      "45761\n",
      "45781\n",
      "45828\n",
      "45829\n",
      "45903\n",
      "45904\n",
      "45905\n",
      "45906\n",
      "45950\n",
      "45955\n",
      "45958\n",
      "45999\n",
      "46021\n",
      "46046\n",
      "46060\n",
      "46118\n",
      "46153\n",
      "46154\n",
      "46155\n",
      "46156\n",
      "46207\n",
      "46208\n",
      "46267\n",
      "46268\n",
      "46311\n",
      "46312\n",
      "46350\n",
      "46351\n",
      "46352\n",
      "46353\n",
      "46354\n",
      "46355\n",
      "46356\n",
      "46357\n",
      "46358\n",
      "46359\n",
      "46361\n",
      "46362\n",
      "46363\n",
      "46364\n",
      "46365\n",
      "46366\n",
      "46367\n",
      "46368\n",
      "46369\n",
      "46370\n",
      "46371\n",
      "46372\n",
      "46373\n",
      "46374\n",
      "46375\n",
      "46376\n",
      "46435\n",
      "46437\n",
      "46448\n",
      "46456\n",
      "46457\n",
      "46458\n",
      "46459\n",
      "46460\n",
      "46467\n",
      "46468\n",
      "46563\n",
      "46728\n",
      "46729\n",
      "46730\n",
      "46731\n",
      "46732\n",
      "46733\n",
      "46734\n",
      "46735\n",
      "46736\n",
      "46737\n",
      "46738\n",
      "46739\n",
      "46740\n",
      "46741\n",
      "46742\n",
      "46743\n",
      "46744\n",
      "46745\n",
      "46746\n",
      "46747\n",
      "46748\n",
      "46749\n",
      "46750\n",
      "46751\n",
      "46752\n",
      "47117\n",
      "47118\n",
      "47119\n",
      "47120\n",
      "47121\n",
      "47122\n",
      "47123\n",
      "47124\n",
      "47125\n",
      "47126\n",
      "47148\n",
      "47171\n",
      "47172\n",
      "47173\n",
      "47174\n",
      "47175\n",
      "47176\n",
      "47177\n",
      "47178\n",
      "47179\n",
      "47180\n",
      "47181\n",
      "47182\n",
      "47183\n",
      "47184\n",
      "47185\n",
      "47186\n",
      "47187\n",
      "47188\n",
      "47189\n",
      "47190\n",
      "47191\n",
      "47192\n",
      "47193\n",
      "47194\n",
      "47195\n",
      "47196\n",
      "47197\n",
      "47198\n",
      "47199\n",
      "47200\n",
      "47201\n",
      "47202\n",
      "47203\n",
      "47204\n",
      "47205\n",
      "47206\n",
      "47207\n",
      "47208\n",
      "47214\n",
      "47216\n",
      "47217\n",
      "47218\n",
      "47223\n",
      "47256\n",
      "47257\n",
      "47258\n",
      "47288\n",
      "47371\n",
      "47383\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 47430 is out of bounds for axis 1 with size 47430",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\ourrec\\data_utils.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ourrec/data_utils.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m f \u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ourrec/data_utils.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50000\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ourrec/data_utils.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(combined_matrix[:,i]\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m :\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ourrec/data_utils.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39mprint\u001b[39m(i)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ourrec/data_utils.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(f)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 47430 is out of bounds for axis 1 with size 47430"
     ]
    }
   ],
   "source": [
    "f =0\n",
    "for i in range(50000):\n",
    "    if len(combined_matrix[:,i].nonzero()[0]) == 0 :\n",
    "        print(i)\n",
    "      \n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "866"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2005, 23042]\n"
     ]
    }
   ],
   "source": [
    "values = [adjacency_matrix.shape[0], adjacency_matrix.shape[1]]\n",
    "\n",
    "# Calculate cumulative sum\n",
    "cumulative_indices = np.cumsum(values).tolist()\n",
    "\n",
    "print(cumulative_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radom_negative_sample(user_action, item_size):\n",
    "    \"\"\"to get (user_size, 100, 2), 100th item is positive one\"\"\"\n",
    "    negative_sample = []\n",
    "    for u in user_action:\n",
    "        sample = []\n",
    "        i = 0\n",
    "        while i < 99:\n",
    "            t = random.randint(0, item_size-1)\n",
    "            if t not in user_action[u]:\n",
    "                sample.append([u, t])\n",
    "                i += 1\n",
    "        sample.append([u, user_action[u][-1]])\n",
    "        negative_sample.append(sample)\n",
    "    return np.array(negative_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2005, 100, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct negatives for the last item in each user's training set\n",
    "negatives = radom_negative_sample(user_concept_dict, len(concept2index))\n",
    "negatives.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856067, 858072)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(rating_matrix)>0).sum(), (np.array(adjacency_matrix)>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 387)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rating_matrix[0]>0).sum(), adjacency_matrix[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_action (2005, 21037)\n",
      "rating_matrix (2005, 21037)\n",
      "all_adjacency_matrix (47430, 47430)\n",
      "adjacency_matrix (2005, 21037)\n",
      "UC (2005, 600)\n",
      "UCT (2005, 1385)\n",
      "US (2005, 137)\n",
      "UV (2005, 22403)\n",
      "negatives (2005, 100, 2)\n"
     ]
    }
   ],
   "source": [
    "# check shape\n",
    "print(\"user_action\", np.array(user_action).shape)\n",
    "print(\"rating_matrix\", np.array(rating_matrix).shape)\n",
    "print(\"all_adjacency_matrix\", np.array(combined_matrix).shape)\n",
    "print(\"adjacency_matrix\", np.array(adjacency_matrix).shape)\n",
    "#print(\"UK\", np.array(user_kc).shape)\n",
    "print(\"UC\", np.array(user_course).shape)\n",
    "print(\"UCT\", np.array(user_teacher).shape)\n",
    "print(\"US\", np.array(user_school).shape)\n",
    "print(\"UV\", np.array(user_video).shape)\n",
    "print(\"negatives\", negatives.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\user\\Desktop\\Heterogeneous\\kgc-rec\\data/all_adjacency_matrix.p', 'wb') as f:\n",
    "    pickle.dump(np.asmatrix(combined_matrix), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/KC.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\ourrec\\data_utils.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ourrec/data_utils.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mdata/KC.p\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ourrec/data_utils.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(np\u001b[39m.\u001b[39masmatrix(cc_np), f)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/ourrec/data_utils.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdata/teacher_concept.p\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\hetero\\lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/KC.p'"
     ]
    }
   ],
   "source": [
    "with open('data/KC.p', 'wb') as f:\n",
    "    pickle.dump(np.asmatrix(cc_np), f)\n",
    "with open('data/teacher_concept.p', 'wb') as f:\n",
    "    pickle.dump(np.asmatrix(teacher_action), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the files from paper repository\n",
    "with open('data/user_action.p', 'wb') as f:\n",
    "    pickle.dump(np.asmatrix(user_action), f)\n",
    "with open('data/rate_matrix.p', 'wb') as f:\n",
    "    pickle.dump(np.asmatrix(rating_matrix), f)\n",
    "with open('data/adjacency_matrix.p', 'wb') as f:\n",
    "    pickle.dump(np.asmatrix(adjacency_matrix), f)\n",
    "with open('data/all_adjacency_matrix.p', 'wb') as f:\n",
    "    pickle.dump(np.asmatrix(combined_matrix), f)\n",
    "with open('data/UC.p', 'wb') as f:\n",
    "    pickle.dump(np.asmatrix(user_course), f)\n",
    "with open('data/UCT.p', 'wb') as f:\n",
    "    pickle.dump(np.asmatrix(user_teacher), f)\n",
    "with open('data/US.p', 'wb') as f:\n",
    "    pickle.dump(np.asmatrix(user_school), f)\n",
    "with open('data/UV.p', 'wb') as f:\n",
    "    pickle.dump(np.asmatrix(user_video), f)\n",
    "with open('data/negative.p', 'wb') as f:\n",
    "    pickle.dump(negatives, f)\n",
    "with open('data/teacher_concept.p', 'wb') as f:\n",
    "    pickle.dump(np.asmatrix(teacher_action), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.fasttext.load_facebook_model('data/cc.zh.300.bin')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "video_concept = []  # Step 1: Initialize an empty list\n",
    "for v in videos:\n",
    "    vvec = np.zeros(len(concepts))\n",
    "    if v in filtered_vc_rel_dict:\n",
    "        indices = [concept2index[_] for _ in filtered_vc_rel_dict[v] if _ in concept2index]\n",
    "        vvec[indices] = 1\n",
    "    video_concept.append(vvec)\n",
    "with open('data/video_concept.p', 'wb') as f:\n",
    "    pickle.dump(np.asmatrix(video_concept), f)\n",
    "\n",
    "course_concept = []  \n",
    "for c in courses:\n",
    "    cvec = np.zeros(len(concepts)) \n",
    "    if c in filtered_cc_rel_dict:\n",
    "        indices = [concept2index[_] for _ in filtered_cc_rel_dict[c] if _ in concept2index]\n",
    "        cvec[indices] = 1\n",
    "    course_concept.append(cvec)\n",
    "with open('data/course_concept.p', 'wb') as f:\n",
    "    pickle.dump(np.asmatrix(course_concept), f)\n",
    "\n",
    "teacher_df = pd.read_json(r\"C:\\Users\\user\\Desktop\\Heterogeneous\\MOOCCube\\entities\\teacher.json\", lines=True)\n",
    "sentences = teacher_df[teacher_df['id'].isin(teachers)]['about'].tolist()\n",
    "sentences.insert(0, '1')\n",
    "def get_sentence_embedding(sentence, model):\n",
    "    embeddings = [model.wv[word] for word in sentence.split() if word in model.wv]\n",
    "    if embeddings:\n",
    "        return sum(embeddings) / len(embeddings)\n",
    "    else:\n",
    "        print(word)\n",
    "        return None\n",
    "        \n",
    "sentence_embeddings = [get_sentence_embedding(sentence, model) for sentence in sentences]\n",
    "with open('data/teacher_embedding.p', 'wb') as f:\n",
    "    pickle.dump(np.array(sentence_embeddings), f)\n",
    "\n",
    "con_vectors = list()\n",
    "for c in distinct_concepts:\n",
    "    if c in model.wv:  \n",
    "        con_vectors.append(model.wv[c])\n",
    "\n",
    "with open('data/concept_embedding.p', 'wb') as f:\n",
    "    pickle.dump(np.array(con_vectors), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\user\\Desktop\\Heterogeneous\\MOOCCube\\entities/concept.json\", \"r\", encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "docs = list()\n",
    "for l in lines:\n",
    "    json_str = json.loads(l)\n",
    "    docs.append(json_str[\"name\"])\n",
    "    if 'explanation' in json_str:\n",
    "        docs.append(json_str[\"explanation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "z = [list(jieba.cut(i)) for i in docs]\n",
    "model = gensim.models.FastText(z, \n",
    "                               sg=0, # CBOW\n",
    "                               min_n=5,\n",
    "                               max_n=10,\n",
    "                               vector_size=100, # change this line\n",
    "                               window=5,\n",
    "                               negative=10,\n",
    "                               min_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\Heterogeneous\\kgc-rec\\data_utils.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Heterogeneous/kgc-rec/data_utils.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m vocab_keys \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(model\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39mkey_to_index\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Heterogeneous/kgc-rec/data_utils.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m myfile:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Heterogeneous/kgc-rec/data_utils.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     wr \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mwriter(myfile, quoting\u001b[39m=\u001b[39mcsv\u001b[39m.\u001b[39mQUOTE_ALL, delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "vocab_keys = list(model.wv.key_to_index.keys())\n",
    "\n",
    "with open('vocab', 'w', encoding=\"utf8\") as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL, delimiter=\"\\n\")\n",
    "    lines = [l.replace(\"\\n\",\" \") for l in vocab_keys]\n",
    "    wr.writerow(lines)\n",
    "\n",
    "np.savetxt(\"emb.tsv\", model.wv.vectors, delimiter=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
